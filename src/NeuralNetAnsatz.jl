"""
Script: NeuralNetAnsatz
Author:Djamil Lakhdar-Hamina
Date: 06/28/2023
Description:

A script to test quantum monte carlo for calculating ground state 

"""

include("/Users/dlakhdar/physics/GitRepos/Ansatz.jl/src/MetropolisHastings.jl")

using Zygote,Flux

const Ïµ=1.5f0
const xmin1=-1.0f0
const xmax1=1.0f0
const Î»=.01

struct NeuralAnsatz
    chain::Chain
end
  
# function (m::NeuralAnsatz)(x)
   
#     return exp.(m.chain(x)).^2
# end

function (m::NeuralAnsatz)(x)
   
    return exp.(m.chain(x)-.5f0*x.^2)
end

Flux.@functor NeuralAnsatz

âˆ‡(g::Function,ð±::Vector)=gradient(ð±->sum(g(ð±)),ð±)
âˆ‡Â²(g::Function,ð±::Vector)=sum(Diagonal(hessian(ð±->sum(g(ð±)),ð±)))
âˆ‡(g::NeuralAnsatz,ð±::Vector)=gradient(ð±->sum(g(ð±)),ð±)
âˆ‡Â²(g::NeuralAnsatz,ð±::Vector)=sum(Diagonal(hessian(ð±->sum(g(ð±)),ð±)))

chain = Chain(Dense(1, 1000,relu),Dense(1000, 1,relu))
Î¨ = NeuralAnsatz(chain)

Ï•(ð±::Vector)=1/2*ð±[1]^2
HÌ‚(ð±::Vector, Ïˆ::Function)=-âˆ‡Â²(Ïˆ,ð±)/2 .+Ï•(ð±)*Ïˆ(ð±)
Îµâ‚€(ð±::Vector,Ïˆ::Function)=Ïˆ(ð±).^-1 .*HÌ‚(ð±,Ïˆ) ## ground state energy 

Ï•(ð±::Vector)=1/2*ð±[1]^2+Î»*ð±[1]^4
HÌ‚(ð±::Vector, Ïˆ::NeuralAnsatz)=-âˆ‡Â²(Ïˆ,ð±)/2 .+Ï•(ð±)*Ïˆ(ð±)
Îµâ‚€(ð±::Vector,Ïˆ::NeuralAnsatz)=Ïˆ(ð±).^-1 .*HÌ‚(ð±,Ïˆ)
Îµâ‚€(ð±::Float64,Ïˆ::NeuralAnsatz)=Ïˆ(ð±).^-1 .*HÌ‚(ð±,Ïˆ)

function Î”Ïµ(N,ð«,Î¨,HÌ‚,Îµâ‚€,Î˜)
    logâˆ‡0=gradient(()->sum(log.(Î¨([ð«[1]]))),Î˜)
    ð’ª=[1/Î¨([ð«[1]])*HÌ‚([ð«[1]],Î¨).*logâˆ‡0,Îµâ‚€([ð«[1]],Î¨),logâˆ‡0]
    for i in 2:N
        logâˆ‡=gradient(()->sum(log.(Î¨([ð«[i]]))),Î˜)
        ð’ª[1].+=1/Î¨([ð«[i]])*HÌ‚([ð«[i]],Î¨).*logâˆ‡0 ## return grads objects 
        ð’ª[2].+=Îµâ‚€([ð«[i]],Î¨)
        ð’ª[3].+=logâˆ‡
    end 
    return 2.0f32 .*ð’ª[1]  .- 2.0f32 .* ((ð’ª[2]./N)[1] .* ð’ª[3]./N)
end 

function EÌ„(ð±::Vector, Ïˆ::NeuralAnsatz)
    N=length(ð±)
    sum_=0
    for i in 1:N
        sum_+=Îµâ‚€([ð±[i]],Ïˆ)[1]
    end 
    1/N*sum_
end 

function train!(epoch,Ïµ,xmin1,xmax1,N, Î¨,HÌ‚,Îµâ‚€,Î˜,opt)
    println("training with $N sample points and $epoch iterations...")
    for i in 1:epoch
        ð«=metropolis_hastings(Ïµ,xmin1,xmax1,N,x->sum(Î¨([x]).^2))
        g=Î”Ïµ(N,ð«,Î¨,HÌ‚,Îµâ‚€,Î˜) ## custom gradient 
        # @show "iteration $i: $(g.params)"
        Flux.update!(opt,Î˜,g)
    end 
    println("trained!")
    println("Params: $Î˜")
end 

opt=Adam(.1)
N=1000

Î˜=Flux.params(Î¨)
epochs=100

function main()
    @time train!(epochs,Ïµ,xmin1,xmax1,N, Î¨,HÌ‚,Îµâ‚€,Î˜,opt)
    @time EÌ„(metropolis_hastings(Ïµ,xmin1,xmax1,1000,x->sum(Î¨([x]).^2)),Î¨)
end

main()